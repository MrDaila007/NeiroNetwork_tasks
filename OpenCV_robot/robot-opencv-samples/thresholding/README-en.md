<h1 align="center">
  <a href="https://youtu.be/grqoGBd1ch0"><img src="https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples/raw/branch/main/thresholding/img/thr.png" alt="Recognizing colored objects" width="800"></a>
  <br>
	Recognizing colored objects
  <br>
</h1>

<p align="center">
  <a href="https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples/src/branch/main/thresholding/README.md">Russian (Русский)</a> •
  <a href="https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples/src/branch/main/thresholding/README-en.md">English</a> 
</p>

## Samples
<h1 align="center">
  <img src="https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples/raw/branch/main/thresholding/img/chs.png" width="800">
  <br>
	Chasing colored objects
  <br>
</h1>    

<h1 align="center">
  <img src="https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples/raw/branch/main/thresholding/img/laser.png" width="800">
  <br>
	The movement on laser target designation
  <br>
</h1>

<h1 align="center">
  <img src="https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples/raw/branch/main/thresholding/img/line.png" width="800">
  <br>
	The movement along the line
  <br>
</h1>

## Test platform
<h1 align="center">
  <a href=""><img src="https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples/raw/branch/main/thresholding/img/cvbot.png" width="800"></a>
</h1>

Based on Orange pi zero 512mb and webcam. 
More about assembly and installing software [here](https://codeberg.org/TrashRobotics/CVbot)  

## App launch
Downloading the project repository
```shell
git clone https://codeberg.org/TrashRobotics/Robot-OpenCV-Samples.git
```
and run the app
```shell
cd Robot-OpenCV-Samples/thresholding/script4robot
python3 app.py -i (ip-адресс orange pi) -p (порт) -s (последовательный порт)
```
Open a browser and type in
```shell
(ip address orange pi):(port)
```
For example:
```shell
192.168.43.56:5000
```     

For more details about everything else, watch [the video](https://youtu.be/grqoGBd1ch0)
